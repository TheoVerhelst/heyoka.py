<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Neural ODEs &#8212; heyoka.py 3.2.0 documentation</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.c441f2ba0852f4cabcb80105e3a46ae6.css?v=5c8e4cc9" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script src="../_static/documentation_options.js?v=4f6ddb47"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/sphinx-book-theme.7d483ff0a819d6edff12ce0b1ead3928.js?v=b56ca714"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Others" href="../examples_others.html" />
    <link rel="prev" title="Neural Hamiltonian ODEs" href="NeuralHamiltonianODEs.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  
  <h1 class="site-logo" id="site-title">heyoka.py 3.2.0 documentation</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent" role="heading">
 <span class="caption-text">
  Main
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../install.html">
   Installation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../changelog.html">
   Changelog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../breaking_changes.html">
   Breaking changes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../benchmarks.html">
   Benchmarks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../acknowledgement.html">
   Acknowledgement
  </a>
 </li>
</ul>
<p class="caption collapsible-parent" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../basic_tutorials.html">
   Basic
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../tut_taylor_method.html">
     Taylor’s method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20expression%20system.html">
     The expression system
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20adaptive%20integrator.html">
     The adaptive integrator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Customising%20the%20adaptive%20integrator.html">
     Customising the adaptive integrator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ODEs%20with%20parameters.html">
     ODEs with parameters
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Non-autonomous%20systems.html">
     Non-autonomous systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Dense%20output.html">
     Dense &amp; continuous output
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Event%20detection.html">
     Event detection
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../advanced_tutorials.html">
   Advanced
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="Batch%20mode%20overview.html">
     Batch mode
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ensemble_mode.html">
     Ensemble propagations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="parallel_mode.html">
     Parallel mode
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ext_precision.html">
     Computations in extended precision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="arbitrary_precision.html">
     Computations in arbitrary precision
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sympy_interop.html">
     Interoperability with SymPy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="compiled_functions.html">
     Compiled functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ex_system_revisited.html">
     Using the expression system effectively
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pickling.html">
     Pickle support
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="jit_caching.html">
     JIT compilation and caching
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent" role="heading">
 <span class="caption-text">
  Examples
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../examples_astro.html">
   Celestial mechanics and astrodynamics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="The%20restricted%20three-body%20problem.html">
     The restricted three-body problem
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Periodic%20orbits%20in%20the%20CR3BP.html">
     Continuation of Periodic Orbits in the CR3BP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Pseudo%20arc-length%20continuation%20in%20the%20CR3BP.html">
     Pseudo arc-length continuation in the CR3BP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Long%20term%20stability%20of%20Trappist-1.html">
     Long term stability of N-body simulations: the case of Trappist-1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Outer%20Solar%20System.html">
     Brouwer’s law in the outer Solar System
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="projection.html">
     Conserving first integrals via manifold projection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Box%20control%20for%20Formation%20Flying%20Satellites.html">
     Box control in satellite Formation Flying
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Comparing%20coordinate%20systems.html">
     Comparing coordinate systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Inverting%20Kepler%27s%20equation%20in%20ODEs.html">
     Inverting Kepler’s equation in ODEs
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Planetary%20embryos.html">
     Planetary embryos in the inner Solar System
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="mercury_precession.html">
     Mercury’s relativistic precession
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ttv.html">
     Calculating transit timing variations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="vsop2013.html">
     Introduction to the VSOP2013 planetary theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="elp2000.html">
     Introduction to the ELP2000 lunar theory
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="tides_spokes.html">
     Elastic tides
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="lagrangian_propagator.html">
     Lagrange propagation and the state transition matrix
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../examples_event.html">
   Event detection
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="Sampling%20events.html">
     Sampling events
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Poincar%C3%A9%20sections.html">
     Poincaré sections
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="second_integral.html">
     The second integral of motion
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20Keplerian%20billiard.html">
     The Keplerian billiard
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20two-fixed%20elliptic%20billiard.html">
     The two-fixed centres elliptic billiard
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20wavy%20ramp.html">
     The wavy ramp
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20Maxwell-Boltzmann%20distribution.html">
     The Maxwell-Boltzmann distribution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ev_sensitivity.html">
     Computing event sensitivity
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="../examples_ml.html">
   Machine Learning
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="NeuralHamiltonianODEs.html">
     Neural Hamiltonian ODEs
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Neural ODEs
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../examples_others.html">
   Others
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="ensemble_batch_perf.html">
     Evaluating the performance of ensemble &amp; batch mode
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="The%20variational%20equations.html">
     The variational equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Optimal%20Control%20of%20the%20Lotka-Volterra%20equations.html">
     Optimal Control of the Lotka-Volterra equations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="definite_integrals.html">
     Computing definite integrals
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Theme by the <a href="https://ebp.jupyterbook.org">Executable Book Project</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/notebooks/NeuralODEs.ipynb.txt"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/bluescarni/heyoka.py"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/bluescarni/heyoka.py/issues/new?title=Issue%20on%20page%20%2Fnotebooks/NeuralODEs.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


            <!-- Full screen (wrap in <a> to have style consistency -->
            <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                    data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                    title="Fullscreen mode"><i
                        class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/bluescarni/heyoka.py/main?urlpath=lab/tree/doc/notebooks/NeuralODEs.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i>
            Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-variational-equations">
   The Variational Equations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#performance-test">
   Performance test
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#taylor-integrator">
     Taylor Integrator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#scipy-counterpart">
     Scipy Counterpart
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-note-on-the-adjoint-method">
   A note on the Adjoint Method
  </a>
 </li>
</ul>

        </nav>
        
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="neural-odes">
<h1>Neural ODEs<a class="headerlink" href="#neural-odes" title="Link to this heading">¶</a></h1>
<p>We here consider, as already done in the <a class="reference internal" href="NeuralHamiltonianODEs.html"><span class="std std-doc">Neural Hamiltonian ODE</span></a> example, a generic system in the form:</p>
<div class="math notranslate nohighlight">
\[
\dot {\mathbf x} = \mathbf f(\mathbf x, \mathcal N_\theta(\mathbf x))
\]</div>
<p>whose solution is indicated with <span class="math notranslate nohighlight">\(\mathbf x(t; x_0, \theta)\)</span> to explicitly denote the dependance on the initial conditions <span class="math notranslate nohighlight">\(\mathbf x_0\)</span> and the network parameters <span class="math notranslate nohighlight">\(\theta\)</span>.
We refer to these systems as Neural ODEs, a term that has been made popular in the paper,</p>
<p><em>Chen, Ricky TQ, Yulia Rubanova, Jesse Bettencourt, and David K. Duvenaud.</em> “Neural ordinary differential equations.” Advances in neural information processing systems 31 (2018).</p>
<p>where it has been used to indicate a specific form of the above equation, when the state represented the neuronal activity of a Neural Network. We here depart from that terminology and use the term in general for any ODE with a right hand side containing an Artificial Neural Network. All the cases illustrated in the <a class="reference internal" href="NeuralHamiltonianODEs.html"><span class="std std-doc">Neural Hamiltonian ODE</span></a> example are, therefore, also to be considered as special cases of Neural ODEs.</p>
<p>Whenever we have a Neural ODE, it is important to be able to define a training pipeline able to change the neural parameters <span class="math notranslate nohighlight">\(\theta\)</span> as to make some loss decrease.</p>
<p>We indicate such a loss with <span class="math notranslate nohighlight">\(\mathcal L(\mathbf x(t; x_0, \theta))\)</span> and show in this example how to compute, using <em>heyoka</em>, its gradient, and hence how to setup a training pipeline for Neural ODEs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The usual main imports</span>
<span class="kn">import</span> <span class="nn">heyoka</span> <span class="k">as</span> <span class="nn">hy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">scipy.integrate</span> <span class="kn">import</span> <span class="n">solve_ivp</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<p>The gradients we seek can be written as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}{l}
\frac{\partial \mathcal L}{\partial \mathbf x_0} =  \frac{\partial \mathbf x}{\partial \mathbf x_0} \frac{\partial \mathcal L}{\partial \mathbf x}\\
\frac{\partial \mathcal L}{\partial \theta} = \frac{\partial \mathbf x}{\partial \theta} \frac{\partial \mathcal L}{\partial \mathbf x}
\end{array}
\end{split}\]</div>
<p>In the expressions above we know the functional form of <span class="math notranslate nohighlight">\(\mathcal L\)</span> and hence its derivatives w.r.t. <span class="math notranslate nohighlight">\(\mathbf x\)</span>, we thus need to compute the remaining terms, i.e. the ODE sensitivities:</p>
<div class="math notranslate nohighlight">
\[
\mathbf \Phi = \frac{\partial \mathbf x(t)}{\partial \mathbf x_0},
\]</div>
<div class="math notranslate nohighlight">
\[
\boldsymbol \varphi = \frac{\partial \mathbf x(t)}{\partial \boldsymbol \theta}.
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The computation of the ODE sensitivities can be achieved following two methods: the variational equations and the adjoint method. Both methods compute the same quantities and we shall see how they are, ultimately, two version of the same reasoning leading to algorithms sharing a similar complexity, contrary to what sometimes believed / reported in the scientific literature.</p>
</div>
<p>For the sake of clarity we here consider a system in the simplified form:</p>
<div class="math notranslate nohighlight">
\[
\dot {\mathbf x} = \mathcal N_\theta(\mathbf x)
\]</div>
<p>the r.h.s. is a Feed Forward Neural Network and we use the <em>heyoka</em> factory function <code class="docutils literal notranslate"><span class="pre">ffnn()</span></code> to instantiate it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We create the symbols for the network inputs (only one in this frst simple case)</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">hy</span><span class="o">.</span><span class="n">make_vars</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="s2">&quot;y&quot;</span><span class="p">)</span>

<span class="c1"># We define as nonlinearity a simple linear layer</span>
<span class="n">linear</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">inp</span><span class="p">:</span> <span class="n">inp</span>

<span class="c1"># We call the factory to construct the FFNN:</span>
<span class="n">ffnn</span> <span class="o">=</span> <span class="n">hy</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">ffnn</span><span class="p">(</span><span class="n">inputs</span> <span class="o">=</span> <span class="n">state</span><span class="p">,</span> <span class="n">nn_hidden</span> <span class="o">=</span> <span class="p">[</span><span class="mi">16</span><span class="p">],</span> <span class="n">n_out</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">activations</span> <span class="o">=</span> <span class="p">[</span><span class="n">hy</span><span class="o">.</span><span class="n">tanh</span><span class="p">,</span> <span class="n">linear</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ffnn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[(p80 + (p32 * tanh((p64 + (p0 * x) + (p1 * y)))) + (p33 * tanh((p65 + (p2 * x) + (p3 * y)))) + (p34 * tanh((p66 + (p4 * x) + (p5 * y)))) + (p35 * tanh((p67 + (p6 * x) + (p7 * y)))) + (p36 * tanh((p68 + (p8 * x) + (p9 * y)))) + (p37 * tanh((p69 + (p10 * x) + (p11 * y)))) + (p38 * tanh((p70 + (p12 * x) + (p13 * y)))) + (p39 * tanh((p71 + (p14 * x) + (p15 * y)))) + (p40 * tanh((p72 + (p16 * x) + (p17 * y)))) + (p41 * tanh((p73 + (p18 * x) + (p19 * y)))) + (p42 * tanh((p74 + (p20 * x) + (p21 * y)))) + (p43 * tanh((p75 + (p22 * x) + (p23 * y)))) + (p44 * tanh((p76 + (p24 * x) + (p25 * y)))) + (p45 * tanh((p77 + (p26 * x) + (p27 * y)))) + (p46 * tanh((p78 + (p28 * x) + (p29 * y)))) + (p47 * tanh((p79 + (p30 * x) + (p31 * y))))), (p81 + (p48 * tanh((p64 + (p0 * x) + (p1 * y)))) + (p49 * tanh((p65 + (p2 * x) + (p3 * y)))) + (p50 * tanh((p66 + (p4 * x) + (p5 * y)))) + (p51 * tanh((p67 + (p6 * x) + (p7 * y)))) + (p52 * tanh((p68 + (p8 * x) + (p9 * y)))) + (p53 * tanh((p69 + (p10 * x) + (p11 * y)))) + (p54 * tanh((p70 + (p12 * x) + (p13 * y)))) + (p55 * tanh((p71 + (p14 * x) + (p15 * y)))) + (p56 * tanh((p72 + (p16 * x) + (p17 * y)))) + (p57 * tanh((p73 + (p18 * x) + (p19 * y)))) + (p58 * tanh((p74 + (p20 * x) + (p21 * y)))) + (p59 * tanh((p75 + (p22 * x) + (p23 * y)))) + (p60 * tanh((p76 + (p24 * x) + (p25 * y)))) + (p61 * tanh((p77 + (p26 * x) + (p27 * y)))) + (p62 * tanh((p78 + (p28 * x) + (p29 * y)))) + (p63 * tanh((p79 + (p30 * x) + (p31 * y)))))]
</pre></div>
</div>
</div>
</div>
<section id="the-variational-equations">
<h2>The Variational Equations<a class="headerlink" href="#the-variational-equations" title="Link to this heading">¶</a></h2>
<p>As derived already in the examples dedicated to the <a class="reference internal" href="The%20variational%20equations.html"><span class="std std-doc">variational equations</span></a> and to the <a class="reference internal" href="Periodic%20orbits%20in%20the%20CR3BP.html"><span class="std std-doc">periodic orbits in the CR3BP</span></a> the ODE sensitivities can be computed from the differential equations:</p>
<div class="math notranslate nohighlight">
\[
 \frac{d\mathbf \Phi}{dt} = \nabla_\mathbf x \mathcal N_\theta(\mathbf x) \cdot \mathbf \Phi \qquad (n,n) = (n,n) (n,n)
\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[
\frac{d\boldsymbol \varphi}{dt} = \nabla_\mathbf x \mathcal N_\theta(\mathbf x) \cdot \boldsymbol \varphi + \frac{\partial \mathcal N_\theta(\mathbf x)}{\partial \boldsymbol \theta} \qquad (n,N) = (n,n) (n,N) + (n,N) 
\]</div>
<p>where we have reported also the dimensions of the various terms for clarity: <span class="math notranslate nohighlight">\(n\)</span> is the system dimension (2 in our case) and <span class="math notranslate nohighlight">\(N\)</span> the number of parameters (87 in our case).</p>
<p>Now this may all sound very complicated, but <em>heyoka</em> simplifies everything for you, so that the code looks like:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Parametes</span>
<span class="n">dNdtheta</span> <span class="o">=</span> <span class="n">hy</span><span class="o">.</span><span class="n">diff_tensors</span><span class="p">(</span><span class="n">ffnn</span><span class="p">,</span> <span class="n">hy</span><span class="o">.</span><span class="n">diff_args</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
<span class="n">dNdtheta</span> <span class="o">=</span> <span class="n">dNdtheta</span><span class="o">.</span><span class="n">jacobian</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of dNdtheta:&quot;</span><span class="p">,</span> <span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Variables</span>
<span class="n">dNdx</span> <span class="o">=</span> <span class="n">hy</span><span class="o">.</span><span class="n">diff_tensors</span><span class="p">(</span><span class="n">ffnn</span><span class="p">,</span> <span class="n">hy</span><span class="o">.</span><span class="n">diff_args</span><span class="o">.</span><span class="n">vars</span><span class="p">)</span>
<span class="n">dNdx</span><span class="o">=</span> <span class="n">dNdx</span><span class="o">.</span><span class="n">jacobian</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of dNdx:&quot;</span><span class="p">,</span> <span class="n">dNdx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of dNdtheta: (2, 82)
Shape of dNdx: (2, 2)
</pre></div>
</div>
</div>
</div>
<p>To assemble the differential equation we must now give names to all the symbolic variables of all the elements in <span class="math notranslate nohighlight">\(\mathbf \Phi\)</span> and <span class="math notranslate nohighlight">\(\mathbf p\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We define the symbols for phi</span>
<span class="n">symbols_phi</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="c1"># Here we define the symbol for the variations</span>
        <span class="n">symbols_phi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;phi_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">))</span>  
<span class="n">phi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hy</span><span class="o">.</span><span class="n">make_vars</span><span class="p">(</span><span class="o">*</span><span class="n">symbols_phi</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

<span class="c1"># We define the symbols for varphi</span>
<span class="n">symbols_varphi</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
        <span class="c1"># Here we define the symbol for the variations</span>
        <span class="n">symbols_varphi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;varphi_&quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">j</span><span class="p">))</span>  
<span class="n">varphi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">hy</span><span class="o">.</span><span class="n">make_vars</span><span class="p">(</span><span class="o">*</span><span class="n">symbols_varphi</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dNdtheta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>We are now ready to finally assemble the expressions for the right hand side of all the variational equations. This can be elegantly done using the following two lines:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The (variational) equations of motion in matrix form</span>
<span class="n">dphidt</span> <span class="o">=</span> <span class="n">dNdx</span><span class="nd">@phi</span>
<span class="n">dvarphidt</span> <span class="o">=</span>  <span class="n">dNdx</span><span class="nd">@varphi</span> <span class="o">+</span> <span class="n">dNdtheta</span>
</pre></div>
</div>
</div>
</div>
<p>We now assemble a Taylor integrator using the computed expressions for the dynamics. We need to repack everything in tuples (lhs, rhs) where lhs is the expression for the variable corresponding to that ODE (e.g., lhs will be <span class="math notranslate nohighlight">\(x\)</span> for the rhs representing <span class="math notranslate nohighlight">\(\frac{dx}{dt}\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dyn</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c1"># The \dot x = ffnn</span>
<span class="k">for</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">state</span><span class="p">,</span><span class="n">ffnn</span><span class="p">):</span>
    <span class="n">dyn</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">))</span>
<span class="c1"># The variational equations for x0</span>
<span class="k">for</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">dphidt</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">dyn</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">))</span>
<span class="c1"># The variational equations for the thetas</span>
<span class="k">for</span> <span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">varphi</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span><span class="n">dvarphidt</span><span class="o">.</span><span class="n">flatten</span><span class="p">()):</span>
    <span class="n">dyn</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">lhs</span><span class="p">,</span> <span class="n">rhs</span><span class="p">))</span>
    
<span class="c1"># These are the initial conditions on the variational equations (the identity matrix) and zeros </span>
<span class="n">ic_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">state</span><span class="p">))</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">symbols_varphi</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="performance-test">
<h2>Performance test<a class="headerlink" href="#performance-test" title="Link to this heading">¶</a></h2>
<p>Let us profile the speed of Taylor integration in the context of Neural ODE vs the <code class="docutils literal notranslate"><span class="pre">scipy.integrate</span></code> counterpart, used in most existsing tools that provide some easy access to some version of Neural ODEs.</p>
<p>We start with setting up the Taylor Integration. We create random weights and biases for the <code class="docutils literal notranslate"><span class="pre">ffnn</span></code>. We also set a very high tolerance as to match what is commonly done in the context of ML work on Neural ODEs. (This test can be repeated at dfferent tolerances and will mostly allow for a similar conclusion).</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For medium size networks already, the use of the <code class="docutils literal notranslate"><span class="pre">compact_mode</span></code> kwarg is essential as else the triggered LLVM compilation may take a long time.</p>
</div>
<section id="taylor-integrator">
<h3>Taylor Integrator<a class="headerlink" href="#taylor-integrator" title="Link to this heading">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">ta</span> <span class="o">=</span> <span class="n">hy</span><span class="o">.</span><span class="n">taylor_adaptive</span><span class="p">(</span>
    <span class="c1"># The ODEs.</span>
    <span class="n">dyn</span><span class="p">,</span>
    <span class="c1"># The initial conditions.</span>
    <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ic_var</span><span class="p">,</span>
    <span class="c1"># Operate in compact mode.</span>
    <span class="n">compact_mode</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="c1"># Define the tolerance</span>
    <span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- </span><span class="si">%s</span><span class="s2"> seconds --- to build (jit) the Taylor integrator&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- 0.44806766510009766 seconds --- to build (jit) the Taylor integrator
</pre></div>
</div>
</div>
</div>
<p>For this test case we create random weights and biases and we perform the integrtion for a time <span class="math notranslate nohighlight">\(t_f=1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Lets define the random weigths / biases</span>
<span class="n">n_pars</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ta</span><span class="o">.</span><span class="n">pars</span><span class="p">)</span>
<span class="n">nn_wb</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">n_pars</span><span class="p">)</span>

<span class="c1"># And assign them to the Taylor adaptive integrator</span>
<span class="n">ta</span><span class="o">.</span><span class="n">pars</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">nn_wb</span>

<span class="c1"># We will perform our numerical interation for a fixed final time.</span>
<span class="n">tf</span> <span class="o">=</span> <span class="mf">1.</span>
</pre></div>
</div>
</div>
</div>
<p>We now set the initial conditions (thay were already set upon construction, but we here explicitly reset them) and perform the integration. We do this two times, one for the purpose of profiling and one to produce a plot, and hence compute intermediate states.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ta</span><span class="o">.</span><span class="n">state</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ic_var</span>
<span class="n">ta</span><span class="o">.</span><span class="n">time</span><span class="o">=</span><span class="mf">0.</span>

<span class="c1"># For profiling</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">ta</span><span class="o">.</span><span class="n">propagate_until</span><span class="p">(</span><span class="n">tf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- </span><span class="si">%s</span><span class="s2"> seconds --- to propagate using the Taylor scheme&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>

<span class="c1"># For plotting</span>
<span class="n">ta</span><span class="o">.</span><span class="n">state</span><span class="p">[:]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ic_var</span>
<span class="n">ta</span><span class="o">.</span><span class="n">time</span><span class="o">=</span><span class="mf">0.</span>
<span class="n">t_span</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">tf</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sol_t</span> <span class="o">=</span> <span class="n">ta</span><span class="o">.</span><span class="n">propagate_grid</span><span class="p">(</span><span class="n">t_span</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- 0.00026917457580566406 seconds --- to propagate using the Taylor scheme
</pre></div>
</div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This is the timing that corresponds to the evaluation of all gradients (ODEs sensitivities) necessary to train the neuralODE on this one point batch. Larger batches will require linearly more time and thus benefit greatly from the batch version of the Taylor Adaptive integrator, leveraging SIMD instructions.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_span</span><span class="p">,</span> <span class="n">sol_t</span><span class="p">[</span><span class="mi">4</span><span class="p">]);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$t$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;The state evolution (Taylor Integration)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/2f1b947f15038641dccdcbcea05a6eb81bbc43c0e36a3564d794991deb838285.png" src="../_images/2f1b947f15038641dccdcbcea05a6eb81bbc43c0e36a3564d794991deb838285.png" />
</div>
</div>
</section>
<section id="scipy-counterpart">
<h3>Scipy Counterpart<a class="headerlink" href="#scipy-counterpart" title="Link to this heading">¶</a></h3>
<p>We assemble the rhs of our equations for use with the <code class="docutils literal notranslate"><span class="pre">scipy.integrate</span></code> suite. Note the simplicity of use of compiled functions for this task.
This allows us to use identical jitted expressions also for the rhs of the case of the scipy calls. The comparison results are thus to be interpreted solely in the light of different numerical integration techniques.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As it is always the case with compiled functions, here we must take care to pass the variable names in the desired order as to avoid the default lexicographic order which, in this case as well as in most cases, does not correspond with what we have in mind (classical source of bugs).</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Assemble the r.h.s. for scipy-integration</span>
<span class="n">rhs</span> <span class="o">=</span> <span class="n">hy</span><span class="o">.</span><span class="n">make_cfunc</span><span class="p">(</span><span class="n">fn</span> <span class="o">=</span> <span class="p">[</span><span class="n">it</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">dyn</span><span class="p">],</span> <span class="n">compact_mode</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="nb">vars</span> <span class="o">=</span> <span class="n">state</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">phi</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span><span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">varphi</span><span class="o">.</span><span class="n">flatten</span><span class="p">()))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pack the r.h.s. into a func to use the scipy.integrate solve_ivp API</span>
<span class="k">def</span> <span class="nf">dydt</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">nn_wb</span> <span class="o">=</span> <span class="n">nn_wb</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">rhs</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pars</span> <span class="o">=</span> <span class="n">nn_wb</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, lets see how a less precise integration scheme from scipy would perform ….</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">sol</span> <span class="o">=</span> <span class="n">solve_ivp</span><span class="p">(</span><span class="n">fun</span> <span class="o">=</span> <span class="n">dydt</span><span class="p">,</span> <span class="n">t_span</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="n">tf</span><span class="p">),</span> <span class="n">y0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ic_var</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;DOP853&#39;</span><span class="p">,</span> <span class="n">dense_output</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;--- </span><span class="si">%s</span><span class="s2"> seconds --- to propagate&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>--- 0.0016400814056396484 seconds --- to propagate
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sol</span><span class="o">.</span><span class="n">t</span><span class="p">,</span> <span class="n">sol</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;$t$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;$x$&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;The state evolution (Scipy Integration)&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/51562948aa5f3c5b9abeadd5c731e74542ecfa18d88ea7ed0c0cedcd407ef95c.png" src="../_images/51562948aa5f3c5b9abeadd5c731e74542ecfa18d88ea7ed0c0cedcd407ef95c.png" />
</div>
</div>
<p>We see a net advantage in timings using the Taylor integration scheme. Note we are here not using batch propagation, which would add an additional 2-4 factor speedup in performances.</p>
</section>
</section>
<section id="a-note-on-the-adjoint-method">
<h2>A note on the Adjoint Method<a class="headerlink" href="#a-note-on-the-adjoint-method" title="Link to this heading">¶</a></h2>
<p>In the above code we have used the variational equations to compute the ODE sensitivities. It is instead common in the ML community to also use the adjoint method instead. In this paragraph we show how the two things are very related and thus one must expect the complexity of the resulting algorithms to also be similar, and hence our conclusions above to hold in general.</p>
<p>Let us, for a moment, instead of seeking <span class="math notranslate nohighlight">\(\frac{\partial \mathbf x(t)}{\partial \mathbf x_0}\)</span>, seek the opposite, and thus define:</p>
<div class="math notranslate nohighlight">
\[
\mathbf a = \frac{\partial \mathbf x_0}{\partial \mathbf x(t)}.
\]</div>
<p>By definition <span class="math notranslate nohighlight">\(\mathbf a\)</span> is the inverse of <span class="math notranslate nohighlight">\(\mathbf \Phi\)</span>, which implies <span class="math notranslate nohighlight">\(\mathbf a = \mathbf \Phi^{-1}\)</span> and thus we also have (accounting fo the fact that the derivative of a matrix inverse is <span class="math notranslate nohighlight">\(\frac{d\mathbf A^{-1}}{dt} = - \mathbf A^{-1}\frac{d \mathbf A}{dt}\mathbf A^{-1}\)</span>):</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathbf a}{\partial t} = - \mathbf \Phi^{-1} \frac{\partial \mathbf \Phi}{\partial t} \mathbf \Phi^{-1} =- \mathbf \Phi^{-1} \nabla_\mathbf x \mathcal N_\theta(\mathbf x)  \mathbf \Phi  \mathbf \Phi^{-1} = -\mathbf a \nabla_\mathbf x \mathcal N_\theta(\mathbf x),
\]</div>
<p>which is a very compact and elegant demonstration (I know right?) of the adjoint equation for our case, otherwise often derived using the calculus of variations and a much more lengthy sequence of variational identities.</p>
<p>More importantly the derivation shows how the adjoint method is strongly related to the variational equations and thus the resulting algorithm complexity cannot, and will not be different.</p>
<p>In the classic derivation of the adjoint method the sensitivities are taken with respect to <span class="math notranslate nohighlight">\(\mathbf x(T)\)</span> and not <span class="math notranslate nohighlight">\(\mathbf x_0 = \mathbf x(t_0)\)</span>. This is irrelevant for the purpose of the demonstration as <span class="math notranslate nohighlight">\(t_0\)</span> is just a point in time and can represent a point in the future as well as a point in the past.</p>
<p>In the paper “Neural ordinary differential equations” which popularized the use of ffnn on the r.h.s od ODEs, the derivation is made for a loss <span class="math notranslate nohighlight">\(\mathcal L\)</span>, and and ODE is seeked for <span class="math notranslate nohighlight">\(\mathbf {\hat a} = \frac{\partial \mathcal L(\mathbf x(T))}{\partial \mathbf x(t)}\)</span>.</p>
<p>Since:</p>
<div class="math notranslate nohighlight">
\[
\mathbf {\hat a} = \frac{\partial \mathcal L(\mathbf x(T))}{\partial \mathbf x(t)} = \frac{\partial \mathcal L(\mathbf x(T))}{\partial \mathbf x(T)}\frac{\partial \mathbf x(T)}{\partial \mathbf x(t)},
\]</div>
<p>it is easy to see that the same differential equation we proved above holds for <span class="math notranslate nohighlight">\(\mathbf {\hat a}\)</span> by taking the time derivatoive of the above identity and noting that <span class="math notranslate nohighlight">\(\frac{\partial \mathcal L(\mathbf x(T))}{\partial \mathbf x(T)}\)</span> is a constant.</p>
</section>
</section>


              </div>
              
        
        <div class='prev-next-bottom'>
            
    <a class='left-prev' id="prev-link" href="NeuralHamiltonianODEs.html" title="previous page">Neural Hamiltonian ODEs</a>
    <a class='right-next' id="next-link" href="../examples_others.html" title="next page">Others</a>

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Francesco Biscani and Dario Izzo<br/>
        
            &copy; Copyright 2020, 2021, 2022, 2023, Francesco Biscani and Dario Izzo.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>